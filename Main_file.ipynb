{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "    return directory\n",
    "\n",
    "def FindDel(S):\n",
    "    \"\"\"This function takes a the first string in a list,(S) that starts with ENG, it finds the nomancature \n",
    "    the file uses for the begining of each file, e.g ENG44007 or ENGINX00305258, it shall also work if more numbers\n",
    "    are added or the name changes so long as ENG followed by anything other than \".\" or \"_\" or \" \" is still \n",
    "    the start of each file\"\"\"\n",
    "    for i in S:\n",
    "        if i[0:3] == 'ENG':\n",
    "            n = 1\n",
    "            for j in i:\n",
    "                if j == '.':\n",
    "                    break\n",
    "                elif j == ' ':\n",
    "                    break\n",
    "                elif j == '_':\n",
    "                    break\n",
    "                else: \n",
    "                    n += 1 \n",
    "            return n\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "def InitialRun(S):\n",
    "    \"\"\"This takes S a list of filenames and returns the first run index\"\"\"\n",
    "    last_int_index = FindDel(S) -1\n",
    "    first_int_index = 0 \n",
    "    for i in S:                                                          \n",
    "        if i[0:3] == 'ENG':\n",
    "            for j in range(last_int_index):\n",
    "                try:\n",
    "                    int(i[j])\n",
    "                    run_number = i[first_int_index:last_int_index]\n",
    "                    break\n",
    "                except:\n",
    "                    first_int_index += 1\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    return((run_number))\n",
    "\n",
    "def CycleRuns(S):\n",
    "    \"\"\"This takes a list of filenames and returns a list of all the runs in the file\"\"\"\n",
    "    Start_run = int(InitialRun(S))\n",
    "    Last_run = int(InitialRun(reversed(S)))\n",
    "    Runs = range(Start_run,Last_run)\n",
    "    return (list(Runs))\n",
    "\n",
    "def RunIndex(s,n): #ENGINX00305258\n",
    "    \"\"\"s is a string in the for m of a filename from the enginx data and returns it's run number, n is the FindDel\"\"\"\n",
    "    last_int_index = n-1\n",
    "    first_int_index = 0\n",
    "    for j in range(last_int_index):\n",
    "        try:\n",
    "            int(s[j])\n",
    "            return s[first_int_index:last_int_index]\n",
    "        except:\n",
    "            first_int_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making spreadsheet of file names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory = \"D:\\\\\"\n",
    "array_names = []\n",
    "file_years = []\n",
    "long_array_names = []\n",
    "for foldername in os.listdir(directory):\n",
    "    if foldername[0:5] == 'cycle':\n",
    "        n = FindDel(os.listdir(\"D:\\\\\"+foldername))\n",
    "        print(n)\n",
    "        for filename in os.listdir(\"D:\\\\\"+foldername):\n",
    "            if filename[n:] in array_names: #stop repeated file names from entering \n",
    "                pass\n",
    "            elif len(filename) < n+1: # Stop useless file names from entering (e.g copy)\n",
    "                pass\n",
    "            elif filename[n] in (\"S\", \"s\", \"N\", \"n\"):# Stop temporary files from entering (e.g .s01 or .n001)\n",
    "                try:\n",
    "                    int(filename[n+1]) # all temp files are 's' or 'n' followed by a int\n",
    "                    temp_files.append(filename)\n",
    "                except ValueError: \n",
    "                    array_names.append(filename[n:])\n",
    "                    long_array_names.append(filename)\n",
    "                    file_years.append(foldername)\n",
    "            else: # most unique file names go here \n",
    "                array_names.append(filename[n:])\n",
    "                long_array_names.append(filename)\n",
    "                file_years.append(foldername)\n",
    "                \n",
    "#print(file_years)\n",
    "#print(array_names)\n",
    "#print(long_array_names)\n",
    "\n",
    "workbook   = xlsxwriter.Workbook('Filenames.xlsx')\n",
    "\n",
    "worksheet1 = workbook.add_worksheet()\n",
    "worksheet2 = workbook.add_worksheet()\n",
    "\n",
    "worksheet1.write_column('A1', array_names)\n",
    "worksheet2.write_column('A1', long_array_names)\n",
    "worksheet1.write_column('B1', file_years)\n",
    "worksheet2.write_column('B1', file_years)\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"D:\\\\\"\n",
    "time = np.array([])\n",
    "Experiment_index = np.array([])\n",
    "for foldername in os.listdir(directory):\n",
    "    if foldername[0:5] == 'cycle':\n",
    "        n = FindDel(os.listdir(\"D:\\\\\"+foldername))\n",
    "        print(n)\n",
    "        for filename in os.listdir(\"D:\\\\\"+foldername):\n",
    "            if filename[-4:] == \".txt\":\n",
    "                file_path = directory+foldername+\"\\\\\"+filename\n",
    "                df = pd.read_csv(file_path, sep = \"\\t\", names = [\"Date\\time\", \"other\"])\n",
    "                li = df[\"Date\\time\"].values\n",
    "                if os.stat(file_path).st_size == 0: # remove empty files\n",
    "                    pass\n",
    "                elif len(str(df.iloc[0].values[0])) < 18: # remove the files without time in the first colmn\n",
    "                    print(filename)\n",
    "                    pass\n",
    "                elif li[0][10] ==\"T\":\n",
    "                    for i in range(len(li)): # fix the T issue in some times \n",
    "                        untdate = li[0].replace('T',' ')\n",
    "                        li = np.append(li,[untdate])\n",
    "                        li = np.delete(li,[0], axis = None)\n",
    "                    time = np.concatenate((a,li),axis=None)\n",
    "                    Experiment_index = np.append(Experiment_index,[filename[:n-1]])\n",
    "                else: # Normal time columns\n",
    "                    time = np.concatenate((a,li),axis=None)\n",
    "                    Experiment_index = np.append(Experiment_index,[filename[:n-1]])\n",
    "                    #print(a)\n",
    "print(len(time))\n",
    "print(time)\n",
    "print(Experiment_index)\n",
    "print(len(Experiment_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a dictionary from spreadsheet of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\zahaab\\\\ENGIN_X_DATA_CLEANING\\\\File_names_2013-19.xlsx\"\n",
    "def Translator(path):\n",
    "    xls = pd.ExcelFile(path)\n",
    "    df = xls.parse(sheet_name = \"Sheet1\")\n",
    "    df = df[[\"Filename\", \"Column_name\"]]\n",
    "    df = df.fillna(0)\n",
    "    true_name_translater = dict(zip(df[\"Filename\"],df[\"Column_name\"]))\n",
    "    s = set(true_name_translater.values())\n",
    "    col_names = list(s)\n",
    "    col_names.remove(0)\n",
    "    col_names.append(\"measured_temperature_U\")\n",
    "    col_names.append(\"unregistered_value\")\n",
    "    return true_name_translater, col_names\n",
    "\n",
    "true_name_translater, col_names = Translator(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from raw files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddRawData(run_number):\n",
    "    file_path = output+\"\\\\\"+str(run_number)+\".txt\"\n",
    "    output_file = open(file_path, \"r\")\n",
    "    contents = output_file.read()\n",
    "    split_contents = contents.split(\"kamehameha\") # Had to pick somthing that wouldn't be in data\n",
    "    del split_contents[-1]\n",
    "    clean_split_contents = []\n",
    "    for i,j in zip(split_contents, data):\n",
    "        a = i.replace(\"\\n\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        a = a.split(\" \")\n",
    "        a = list(filter(None, a))\n",
    "        if \"data\" in j:\n",
    "            clean_split_contents.append(j[0:16]+str(run_number))\n",
    "            Neutron_file = open(Neutron_folder+\"\\\\\"+j[0:16]+str(run_number)+\".txt\", \"w+\")\n",
    "            Neutron_file.write(str(a))\n",
    "            Neutron_file.close()\n",
    "        elif \"time\" in j:\n",
    "            untdate = i.replace('T',' ')\n",
    "            clean_split_contents.append(untdate)\n",
    "        else:\n",
    "            clean_split_contents.append(a)\n",
    "    raw_data = dict(zip(data, list(clean_split_contents)))\n",
    "    output_file.close()\n",
    "    os.remove(file_path) \n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeutronDataTranslator(Neutron_key):\n",
    "    Neutron_file = open(Neutron_folder+\"\\\\\"+Neutron_key+\".txt\", \"r\")\n",
    "    contents = Neutron_file.read()\n",
    "    contents = contents.replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    contents = contents.split(\", \")\n",
    "    contents = list(map(float, contents))\n",
    "    Neutron_file.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= r\"C:\\Users\\zahaab\\temp_raw_data\"\n",
    "Neutron_folder = r\"C:\\Users\\zahaab\\Neutron_data\"\n",
    "data = [\"North_neutron_X_data\",\"North_neutron_Y_data\",\"South_neutron_X_data\",\n",
    "            \"South_neutron_Y_data\",\"neutron_start_time\",\"neutron_end_time\",\"Run_Title\"] #neutron data col names\n",
    "raw_data = AddRawData(44296)\n",
    "print(raw_data)\n",
    "North_neutron_X_44296 = NeutronDataTranslator(\"North_neutron_X_44296\")\n",
    "print(North_neutron_X_44296)\n",
    "print(type(North_neutron_X_44296))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making function(s) for extracting data from files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def NewRun(run_number, run_data, time_list, raw_data, file_location):\n",
    "    \"\"\"This activates if a new run has started, it makes a new list of dictionaries and makes a CSV out of current data\"\"\"\n",
    "    df1 = pd.DataFrame(columns = [\"Date/Time\"])\n",
    "    for i in time_list:\n",
    "        row = np.array([i])\n",
    "        column_names = np.array([\"Date/Time\"])\n",
    "        for j in run_data:\n",
    "            try:\n",
    "                row = np.append(row, [j[1][i]])\n",
    "                column_names = np.append(column_names, [j[0]])\n",
    "            except:\n",
    "                pass\n",
    "        df2 = pd.DataFrame([row], columns = column_names)\n",
    "        df1 = df1.append(df2, sort=False)\n",
    "    df1.set_index(\"Date/Time\", drop=True)\n",
    "    for i in raw_data:\n",
    "        df1[str(i)] = str(raw_data[i])\n",
    "    print(run_number)\n",
    "    print(file_location)\n",
    "    df1.to_csv(file_location+\"\\\\\"+run_number)\n",
    "    \n",
    "    raw_data = {}\n",
    "    run_data = []\n",
    "    time_list = np.array([])\n",
    "    for i,j in enumerate(col_names):\n",
    "        run_data.append((j,{}))\n",
    "    \n",
    "    return run_data,time_list,raw_data\n",
    "\n",
    "def Find_dict(run_data, trans_filename):\n",
    "    for i,j in enumerate(run_data):\n",
    "        if j[0] == trans_filename:\n",
    "            return i\n",
    "\n",
    "def AddData(file_path, filename, n, run_data, time_list):\n",
    "    \"\"\"This takes data from a txt file and puts it into a list of times and the dictionaries\"\"\"\n",
    "    df = pd.read_csv(file_path, sep = \"\\t\", names = [\"Date/Time\", str(true_name_translater[filename[n:]])])\n",
    "    file_times = df[\"Date/Time\"].values\n",
    "    file_data = df[str(true_name_translater[filename[n:]])].values \n",
    "    dict_index = Find_dict(run_data, true_name_translater[filename[n:]])\n",
    "    if os.stat(file_path).st_size == 0: # remove empty files\n",
    "        pass\n",
    "    elif len(str(df.iloc[0].values[0])) < 18: # remove the files without time in the first colmn\n",
    "        pass\n",
    "    elif file_times[0][10] ==\"T\":\n",
    "        for i in range(len(li)): # fix the T issue in some times \n",
    "            untdate = file_times[0].replace('T',' ')\n",
    "            file_times = np.append(file_times,[untdate])\n",
    "            file_times = np.delete(file_times,0, axis = None)\n",
    "        time_list = np.unique(np.append(time_list, file_times))\n",
    "        for i, j in zip(file_times,file_data):\n",
    "            if \"temperature\" in true_name_translater[filename[n:]]:#Alot of tempreture files, may be some overlap in time\n",
    "                try:\n",
    "                    a = run_data[dict_index][1][i]\n",
    "                    run_data[-2][1][i] = j\n",
    "                except:\n",
    "                    run_data[dict_index][1][i] = j\n",
    "            else:#rest of the files \n",
    "                try:\n",
    "                    a = run_data[dict_index][1][i]\n",
    "                    run_data[-1][1][i] = [run_data[dict_index][0],j]\n",
    "                except:\n",
    "                    run_data[dict_index][1][i] = j\n",
    "    else: # Normal time columns\n",
    "        time_list = np.unique(np.append(time_list, file_times))\n",
    "        for i, j in zip(file_times,file_data):\n",
    "            if \"temperature\" in true_name_translater[filename[n:]]:\n",
    "                try:\n",
    "                    a = run_data[dict_index][1][i]\n",
    "                    run_data[-2][1][i] = j\n",
    "                except:\n",
    "                    run_data[dict_index][1][i] = j\n",
    "            else:\n",
    "                try:\n",
    "                    a = run_data[dict_index][1][i]\n",
    "                    run_data[-1][1][i] = [run_data[dict_index][0],j]\n",
    "                except:\n",
    "                    run_data[dict_index][1][i] = j\n",
    "    return run_data, time_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-25909fd887bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%prun\\ndirec = \"E:\\\\\\\\\"\\noutput= r\"E:\\\\temp_raw_data\"\\nNeutron_folder = r\"E:\\\\Neutron_data\"\\nENGINX_DATA = r\"E:\\\\clean_data\"\\ndata = [\"North_neutron_X_data\",\"North_neutron_Y_data\",\"South_neutron_X_data\",\\n            \"South_neutron_Y_data\",\"neutron_start_time\",\"neutron_end_time\",\"Run_Title\"] #neutron data col names\\n\\n\\nfor foldername in os.listdir(direc):\\n    if foldername[0:5] == \\'cycle\\':\\n        if foldername != \"cycle_04_1\":#just for test\\n            break\\n        folder_path = direc+\"\\\\\\\\\"+foldername\\n        clean_data = CreateFolder(ENGINX_DATA+\"\\\\\\\\\"+foldername)\\n        print(clean_data)\\n        n = FindDel(os.listdir(folder_path))\\n        filenames = os.listdir(folder_path)\\n        raw_data = {}\\n        run_data = []\\n        for i,j in enumerate(col_names):\\n            run_data.append((j,{}))\\n        time_list = np.array([])\\n        finale_file = 0\\n        for k, filename in enumerate(filenames):\\n            print(filename)\\n            file_path = folder_path+\\'\\\\\\\\\\'+filename\\n            if \"Copy\" in filename:\\n                pass \\n            elif RunIndex(filenames[k],n) != RunIndex(filenames[k-1],n):\\n                if len(time_list) == 0:\\n                    pass\\n                else:\\n                    run_data,time_list,raw_data = NewRun(RunIndex(filenames[k-1],n), run_data, time_list, raw_data, clean_data)\\n                    if filename[-3:].lower() == \"raw\":\\n                        raw_data = AddRawData(RunIndex(filenames[k],n))\\n                    elif filename[-3:] == \"txt\":\\n                        run_data,time_list = AddData(file_path, filename, n, run_data, time_list)\\n                    else:\\n                        pass\\n            else:\\n                if filename[-3:].lower() == \"raw\":\\n                    raw_data = AddRawData(RunIndex(filenames[k],n))\\n                elif filename[-3:] == \"txt\":\\n                    run_data,time_list = AddData(file_path, filename, n, run_data, time_list)\\n                else:\\n                    pass\\n            finale_file = filenames[k]\\n        NewRun(RunIndex(filenames[k],n), run_data, time_list, raw_data, clean_data)\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2350\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2352\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2353\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Users\\zahaab\\Anaconda3\\lib\\site-packages\\decorator.py:decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1145\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'E:\\\\'"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "%prun\n",
    "direc = \"E:\\\\\"\n",
    "output= r\"E:\\temp_raw_data\"\n",
    "Neutron_folder = r\"E:\\Neutron_data\"\n",
    "ENGINX_DATA = r\"E:\\clean_data\"\n",
    "data = [\"North_neutron_X_data\",\"North_neutron_Y_data\",\"South_neutron_X_data\",\n",
    "            \"South_neutron_Y_data\",\"neutron_start_time\",\"neutron_end_time\",\"Run_Title\"] #neutron data col names\n",
    "\n",
    "\n",
    "for foldername in os.listdir(direc):\n",
    "    if foldername[0:5] == 'cycle':\n",
    "        if foldername != \"cycle_04_1\":#just for test\n",
    "            break\n",
    "        folder_path = direc+\"\\\\\"+foldername\n",
    "        clean_data = CreateFolder(ENGINX_DATA+\"\\\\\"+foldername)\n",
    "        print(clean_data)\n",
    "        n = FindDel(os.listdir(folder_path))\n",
    "        filenames = os.listdir(folder_path)\n",
    "        raw_data = {}\n",
    "        run_data = []\n",
    "        for i,j in enumerate(col_names):\n",
    "            run_data.append((j,{}))\n",
    "        time_list = np.array([])\n",
    "        finale_file = 0\n",
    "        for k, filename in enumerate(filenames):\n",
    "            print(filename)\n",
    "            file_path = folder_path+'\\\\'+filename\n",
    "            if \"Copy\" in filename:\n",
    "                pass \n",
    "            elif RunIndex(filenames[k],n) != RunIndex(filenames[k-1],n):\n",
    "                if len(time_list) == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    run_data,time_list,raw_data = NewRun(RunIndex(filenames[k-1],n), run_data, time_list, raw_data, clean_data)\n",
    "                    if filename[-3:].lower() == \"raw\":\n",
    "                        raw_data = AddRawData(RunIndex(filenames[k],n))\n",
    "                    elif filename[-3:] == \"txt\":\n",
    "                        run_data,time_list = AddData(file_path, filename, n, run_data, time_list)\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                if filename[-3:].lower() == \"raw\":\n",
    "                    raw_data = AddRawData(RunIndex(filenames[k],n))\n",
    "                elif filename[-3:] == \"txt\":\n",
    "                    run_data,time_list = AddData(file_path, filename, n, run_data, time_list)\n",
    "                else:\n",
    "                    pass\n",
    "            finale_file = filenames[k]\n",
    "        NewRun(RunIndex(filenames[k],n), run_data, time_list, raw_data, clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding how to deal with Stress rig data (work in progress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def CombineRigCleanData(cycle):\n",
    "    direct = \"E:\\\\stuff\\\\OtherData\\\\\"+cycle+\"\\\\Stress Rig\"\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    for filename in os.listdir(ENGINX_DATA+\"\\\\\"+cycle):\n",
    "        file_path = ENGINX_DATA+\"\\\\\"+cycle+\"\\\\\"+filename\n",
    "        df2 = pd.read_csv(file_path,index_col=0)\n",
    "        df2[\"Run_Number\"] = filename\n",
    "        df1 = df1.append(df2, ignore_index=False, sort=False)\n",
    "    time_list = df1[\"Date/Time\"].values\n",
    "    df1.set_index(\"Date/Time\") \n",
    "\n",
    "    df3 = pd.DataFrame()\n",
    "    for filename in os.listdir(direct):\n",
    "        file_path = direct+\"\\\\\"+filename\n",
    "        df4 = pd.read_csv(file_path, sep = \"|\", skipinitialspace = True, skiprows = [0,1])\n",
    "        df3 = df3.append(df4, ignore_index=False, sort=False)\n",
    "        input_file = open(file_path+\".txt\", \"r\")\n",
    "        first_line = output_file.readline()\n",
    "        constants = {\"Cross_Sectional_Area\" : first_line[:33].split(\"=\")[-1].replace(\" \", \"\"),\n",
    "                     \"Gauge_Length_for_Strain1\" : first_line[33:].split(\"=\")[-1].replace(\" \", \"\")}\n",
    "        input_file.close()\n",
    "        for i in constants:\n",
    "            df3[str(i)] = str(constants[i]).replace(\"\\n\",\"\")\n",
    "\n",
    "    df3 = df3.rename(index = str, columns = dict(zip(\n",
    "        df3.columns.values.tolist(), ['rig_{0}'.format(i).replace(\" \", \"\") for i in df3.columns.values.tolist()])))\n",
    "    df3 = df3.rename(index = str, columns = {'rig_Date/Time' : 'Date/Time'})\n",
    "\n",
    "    #df3.set_index(\"Date/Time\")\n",
    "    #df3 = df3.loc[~df3.index.duplicated(keep='first')] #drop duplicates \n",
    "    df3 = df3.loc[~df3[\"Date/Time\"].duplicated(keep='first')]\n",
    "    df5 = df3.loc[df3[\"Date/Time\"].isin(time_list)]\n",
    "    result = pd.concat([df5, df1], axis=1, sort=False, join='outer')\n",
    "\n",
    "    return(result) \n",
    "\n",
    "def CleanInstron01(cycle, filenames, clean_file_time):\n",
    "    direct = r\"E:\\stuff\\OtherData\\INSTRON_01\"\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    for filename in os.listdir(ENGINX_DATA+\"\\\\\"+cycle):\n",
    "        file_path = ENGINX_DATA+\"\\\\\"+cycle+\"\\\\\"+filename\n",
    "        df2 = pd.read_csv(file_path,index_col=0)\n",
    "        df2[\"Run_Number\"] = filename\n",
    "        df1 = df1.append(df2, ignore_index=False, sort=False)\n",
    "    time_list = df1[\"Date/Time\"].values\n",
    "    df1.set_index(\"Date/Time\") \n",
    "    \n",
    "    #find the files that needed for the spesific cycle\n",
    "    cycle_start, cycle_end = time_list[0], time_list[-1]\n",
    "    start_file_index, end_file_index = 0, 0\n",
    "    for i in clean_file_time:\n",
    "        if datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\") > datetime.strptime(cycle_start, \"%Y-%m-%d %H:%M:%S\"):\n",
    "            start_file_index = clean_file_time.index(i)-1\n",
    "            break \n",
    "    for i in clean_file_time.reverse():\n",
    "        if datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\") < datetime.strptime(cycle_start, \"%Y-%m-%d %H:%M:%S\")::\n",
    "            end_file_index = (clean_file_time.index(i)+1)*-1\n",
    "            break \n",
    "    \n",
    "    if start_file_index, end_file_index == 0,0:#Logic needs to be fixed\n",
    "        return(df1)\n",
    "    \n",
    "    df3 = pd.DataFrame()\n",
    "    for filename in os.listdir(direct)[start_file_index, end_file_index+1]:\n",
    "        file_path = direct+\"\\\\\"+filename\n",
    "        df4 = pd.read_csv(file_path, sep = \"\\t\", skipinitialspace = True, skiprows = [0,1,2,3])\n",
    "        df3 = df3.append(df4, ignore_index=False, sort=False)\n",
    "        input_file = open(file_path+\".txt\", \"r\")\n",
    "        first_line, second_line, third_line = output_file.readline(), output_file.readline(1), output_file.readline(2)\n",
    "        constants = {\"Cross_Sectional_Area\" : first_line.split(\"=\")[-1].replace(\" \", \"\"),\n",
    "                     \"Gauge_Length_for_Strain1\" : second_line.split(\"=\")[-1].replace(\" \", \"\"),\n",
    "                     \"RB Number\" : third_line.split(\"=\")[-1].replace(\" \", \"\")}\n",
    "        input_file.close()\n",
    "        for i in constants:\n",
    "            df3[str(i)] = str(constants[i]).replace(\"\\n\",\"\")\n",
    "        \n",
    "    df3 = df3.rename(index = str, columns = dict(zip(\n",
    "        df3.columns.values.tolist(), ['rig_{0}'.format(i).replace(\" \", \"\") for i in df3.columns.values.tolist()])))\n",
    "    df3 = df3.rename(index = str, columns = {'rig_Date/Time' : 'Date/Time'})\n",
    "    df3 = df3.loc[~df3[\"Date/Time\"].duplicated(keep='first')]\n",
    "    \n",
    "    unttime = []\n",
    "    for i in df3[\"Date/Time\"].values:\n",
    "        untdate = \"{}-{}-{} {}:{}:{}\".format(\n",
    "            date[0:4], date[5:7], date[8:10], date[11:13], date[14:16], date[17:19])\n",
    "        unttime.append(untdate)\n",
    "    df3 = df3.drop(columns=[\"Date/Time\"])\n",
    "    df3[\"Date/Time\"] = unttime\n",
    "    \n",
    "    df5 = df3.loc[df3[\"Date/Time\"].isin(time_list)]\n",
    "    result = pd.concat([df5, df1], axis=1, sort=False, join='outer')\n",
    "    return(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-905ec2d5b8fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mENGINX_DATA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"E:\\clean_data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minstron_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mENGINX_DATA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"E:\\stuff\\OtherData\\INSTRON_01\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ENGINX_DATA = r\"E:\\clean_data\"\n",
    "\n",
    "instron_start = len(os.listdir(ENGINX_DATA))\n",
    "\n",
    "filenames = os.listdir(r\"E:\\stuff\\OtherData\\INSTRON_01\")\n",
    "clean_file_time = []\n",
    "for filename in filenames:\n",
    "    if \"continuous\" in filename:\n",
    "        filenames.remove(filename)\n",
    "    else: \n",
    "        date = filename[11:]\n",
    "        untdate = \"{}-{}-{} {}:{}:{}\".format(\n",
    "        date[0:4], date[5:7], date[8:10], date[11:13], date[14:16], date[17:19])\n",
    "        clean_file_time.append(untdate)\n",
    "            \n",
    "for i,j in  enumerate(os.listdir(ENGINX_DATA)):\n",
    "    if j == \"cycle_17_3\":\n",
    "        CombineRigCleanData(j)\n",
    "        instron_start = i\n",
    "    elif i > instron_start:\n",
    "        CleanInstron01(j, filenames, clean_file_time)\n",
    "    else:\n",
    "        CombineRigCleanData(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
